---
title: "FA542 - Final Exam"
subtitle: "I pledge my honor that I have abided by the Stevens Honor System."
author: "Sid Bhatia"
date: "2023-12-13"
output: pdf_document
---

## Problem 1 (50pt)

Suppose that the daily log return of a pair of securities follows the following model:

$$
\left\{\begin{array}{l}
r_{1, t}=-0.05+0.1 r_{1, t-1}+0.05 r_{2, t-1}+a_{1, t} \\
r_{2, t}=0.1-0.1 r_{1, t-1}+0.3 r_{2, t-1}+a_{2, t}
\end{array}\right.
$$

where $a_t$ denotes a bivariate normal distribution with mean $0$ and covariance:

$$
\Sigma:=\left(\begin{array}{cc}
0.4 & -0.1 \\
-0.1 & 0.2
\end{array}\right)
$$

Any matrix operations can be computed in R. If any formulas require infinite series, you may approximate using the first 5 terms.

#### a. 

 Verify that the return series ${r_t}$ is a weakly stationary process.

 *Hint*: The “polyroot” function can be used to find all roots of a polynomial in R and the “eigen” function can be used to find all eigenvalues of a matrix in R.

 
```{r}
# Defining the coefficient matrix for the mean calculation
A <- matrix(c(1 - 0.1, -0.05, 0.1, 1 - 0.3), nrow = 2, byrow = TRUE)

# Defining the constant terms
B <- c(-0.05, 0.1)

# Solving for mu (the mean of r1 and r2).
mu <- solve(A, B)

# Defining the coefficient matrix for the characteristic equation.
char_matrix <- matrix(c(-0.1, 0.1, -0.05, -0.3), nrow = 2, byrow = TRUE)

# Calculating the eigenvalues of the characteristic matrix.
eigenvalues <- eigen(char_matrix)$values

# Display the results.
print("Means of r1 and r2:")
mu

print("Eigenvalues of the characteristic matrix:")
eigenvalues

# Check if the absolute values of eigenvalues are less than 1 (inside the unit circle).
is_stationary <- all(abs(eigenvalues) < 1)

# Display the conclusion.
if (is_stationary) 
{
  print("The series is weakly stationary.")
} else 
{
  print("The series is not weakly stationary.")
}
```

#### b.

##### i.

What is the mean vector of the return series $r_t$?

```{r}
mu
```

##### ii.

What is the covariance matrix of the return series $r_t$?

```{r}
library(MASS) # For solving Yule-Walker equations

# Covariance matrix
Sigma <- matrix(c(0.4, -0.1, -0.1, 0.2), nrow = 2, byrow = TRUE)
phi <- matrix(c(0.1, 0.05, -0.1, 0.3), nrow = 2, byrow = TRUE)

# Solving Yule-Walker equations
cov_matrix <- solve(toeplitz(1:2), Sigma)

cov_matrix
```

##### iii.

What are the lag-1, lag-2, and lag-5 cross-correlation matrices of the return series $r_t$?

```{r}
# Create a function to compute the cross-correlation matrix for a given lag.
compute_cross_corr <- function(lag, phi, cov_matrix) 
{
    if (lag == 0) {
        return(cov_matrix)
    } else {
        return(phi %*% compute_cross_corr(lag - 1, phi, cov_matrix))
    }
}

lag1_corr <- compute_cross_corr(1, phi, cov_matrix)
lag2_corr <- compute_cross_corr(2, phi, cov_matrix)
lag5_corr <- compute_cross_corr(5, phi, cov_matrix)

lag1_corr
lag2_corr
lag5_corr
```

#### c.

Assume that $r_0 = (-0.02, 0.08)^{\top}$ and $a_0 = (-0.08, 0.1)^{\top}$. Compute the 1-, 2-, and 3-step ahead forecasts of the return series at the forecast origin $t = 1$. What are the covariance matrices of the associated forecast errors?

```{r}
# Initial values
r0 <- matrix(c(-0.02, 0.08), nrow = 2)
a0 <- matrix(c(-0.08, 0.1), nrow = 2)

constant <- matrix(c(-0.05, 0.1), nrow = 2)

# Function to compute the forecast.
forecast <- function(h, r0, a0, phi, constant) {
  if (h == 0) {
    return(r0)
  } else {
    return(phi %*% forecast(h - 1, r0, a0, phi, constant) + constant)
  }
}

# Compute forecasts.
forecast_1 <- forecast(1, r0, a0, phi, constant)
forecast_2 <- forecast(2, r0, a0, phi, constant)
forecast_3 <- forecast(3, r0, a0, phi, constant)

forecast_1
forecast_2
forecast_3

# Compute forecast errors.
forecast_error_cov_1 <- Sigma
forecast_error_cov_2 <- phi %*% Sigma %*% t(phi) + Sigma
forecast_error_cov_3 <- phi %*% forecast_error_cov_2 %*% t(phi) + Sigma

forecast_error_cov_1
forecast_error_cov_2
forecast_error_cov_3
```

#### d.

Create a report in pdf format and do the following:

##### i.

Simulate 1000 terms of this time series and plot the result.

```{r}
library(ggplot2)

set.seed(100)

# Model parameters.
phi <- matrix(c(0.1, 0.05, -0.1, 0.3), nrow = 2, byrow = TRUE)
constant <- c(-0.05, 0.1)
Sigma <- matrix(c(0.4, -0.1, -0.1, 0.2), nrow = 2, byrow = TRUE)
n <- 1000 # Number of terms to simulate

# Simulating the time series.
r <- matrix(nrow = n, ncol = 2)
r[1, ] <- c(-0.02, 0.08) # Initial value

# Simulating the time series
for (i in 2:n) {
  a_t <- mvrnorm(1, mu = c(0, 0), Sigma = Sigma)
  r[i, ] <- constant + phi %*% r[i - 1, ] + a_t
}

# Plotting the result.
df <- data.frame(Time = 1:n, r1 = r[, 1], r2 = r[, 2])

# Plotting the simulated time series.
plot(df$Time, df$r1, type = "l", col = "blue", xlab = "Time", ylab = "Returns", main = "Simulated Time Series")
lines(df$Time, df$r2, type = "l", col = "red")
legend("topright", legend = c("r1", "r2"), col = c("blue", "red"), lty = 1)
```

##### ii.

Using the generated time series, find the sample mean and covariance. How does your sample mean vector compare with that computed analytically?

```{r}
sample_mean <- colMeans(r)
sample_cov <- cov(r)

sample_mean
sample_cov

comparison <- data.frame(Sample_Mean = sample_mean, Analytical_Mean = mu)

comparison
```

The comparison of the sample means from the simulation with the analytical means calculated using the model parameters for $r_1$ and $r_2$ shows some differences, though they are not substantial.

For $r_1$, the sample mean ($-0.05285271$) is slightly lower than the analytical mean ($-0.04724409$), and for $r_2$, the sample mean ($0.14119421$) is also lower compared to the analytical mean ($0.14960630$).

Despite these differences in magnitude, the signs of the means are consistent, indicating that the simulation captures the directional trend of the data as predicted by the model. These variances are expected due to the inherent randomness in the simulation process and potential approximations in the model.

##### iii.

Using the generated time series, find the sample lag-1, lag-2, and lag-5 crosscorrelation matrices.

```{r}
# Function to extract cross-correlation matrix at a specific lag.
get_lag_corr <- function(data, lag) {
    # Computing cross-correlation for each pair
    corr_r1_r1 <- ccf(data[,1], data[,1], lag.max = lag, plot = FALSE)$acf[lag + 1]
    corr_r1_r2 <- ccf(data[,1], data[,2], lag.max = lag, plot = FALSE)$acf[lag + 1]
    corr_r2_r1 <- ccf(data[,2], data[,1], lag.max = lag, plot = FALSE)$acf[lag + 1]
    corr_r2_r2 <- ccf(data[,2], data[,2], lag.max = lag, plot = FALSE)$acf[lag + 1]

    # Constructing the cross-correlation matrix
    matrix(c(corr_r1_r1, corr_r1_r2, corr_r2_r1, corr_r2_r2), nrow = 2)
}

# Calculating the cross-correlation matrices for lags 1, 2, and 5.
lag1_corr <- get_lag_corr(r, 1)
lag2_corr <- get_lag_corr(r, 2)
lag5_corr <- get_lag_corr(r, 5)

lag1_corr
lag2_corr
lag5_corr
```

##### iv.

Consider how you might use repeated simulations to forecast this time series. Use your method with 10,000 repeated simulations of the time series to forecast the 1-, 2-, and 3-step ahead returns with $r_0 = (−0.02, 0.08)^{\top}$ and $a_0 = (−0.08, 0.1)^{\top}$. What is the sample covariance of the errors? How do these values compare with those computed analytically?

```{r}
num_simulations <- 10000
forecast_horizon <- 3

# Initialize matrices to store forecasts and errors.
forecasts <- array(dim = c(num_simulations, forecast_horizon, 2))
errors <- array(dim = c(num_simulations, forecast_horizon, 2))

# Simulate and forecast
for (i in 1:num_simulations) {
  r <- r0
  a <- a0
  for (j in 1:forecast_horizon) {
    # Generate next value.
    r_next <- constant + phi %*% r + a
    # Store forecast.
    forecasts[i, j, ] <- r_next
    # Update r and a for next step.
    r <- r_next
    a <- mvrnorm(1, mu = c(0, 0), Sigma = Sigma)
  }
  # Calculate errors for each forecast step.
  for (j in 1:forecast_horizon) {
    errors[i, j, ] <- forecasts[i, j, ] - r
  }
}

# Compute the sample covariance of the forecast errors.
error_cov_1 <- cov(errors[, 1, ])
error_cov_2 <- cov(errors[, 2, ])
error_cov_3 <- cov(errors[, 3, ])

error_cov_1
error_cov_2
error_cov_3
```

#### e.

Create a report in pdf format and do the following:

##### i.

Simulate 1000 terms of this time series and plot the result. You may use the series constructed in (d)(i).

```{r}
set.seed(100)

# Model parameters.
phi <- matrix(c(0.1, 0.05, -0.1, 0.3), nrow = 2, byrow = TRUE)
constant <- c(-0.05, 0.1)
Sigma <- matrix(c(0.4, -0.1, -0.1, 0.2), nrow = 2, byrow = TRUE)
n <- 1000 # Number of terms to simulate

# Simulating the time series.
r <- matrix(nrow = n, ncol = 2)
r[1, ] <- c(-0.02, 0.08) # Initial value

# Simulating the time series
for (i in 2:n) {
  a_t <- mvrnorm(1, mu = c(0, 0), Sigma = Sigma)
  r[i, ] <- constant + phi %*% r[i - 1, ] + a_t
}

# Plotting the result.
df <- data.frame(Time = 1:n, r1 = r[, 1], r2 = r[, 2])

# Plotting the simulated time series.
plot(df$Time, df$r1, type = "l", col = "blue", xlab = "Time", ylab = "Returns", main = "Simulated Time Series")
lines(df$Time, df$r2, type = "l", col = "red")
legend("topright", legend = c("r1", "r2"), col = c("blue", "red"), lty = 1)
```

##### ii.

Using the generated time series, fit a univariate AR(1) model to each return series.

##### iii.

Compute the mean of both univariate models. How do these compare to those for the bivariate series?

##### iv.

Assume $r_{1,0} = -0.02, r_{2,0} = 0.08, a_{1,0} = -0.08,$ and $a_{2,0} = 0.1$. Compute the 1-, 2-, and 3-step ahead forecasts of both of your univariate return series models at the forecast origin $t = 1$. What are the standard deviations of the associated forecast errors? How do these compare to those for the bivariate series? You may approach this problem either analytically or via simulations.
