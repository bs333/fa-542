---
title: "FA542 - Final Exam"
subtitle: "I pledge my honor that I have abided by the Stevens Honor System."
author: "Sid Bhatia"
date: "2023-12-13"
output: pdf_document
---

## Problem 1 (50pt)

Suppose that the daily log return of a pair of securities follows the following model:

$$
\left\{\begin{array}{l}
r_{1, t}=-0.05+0.1 r_{1, t-1}+0.05 r_{2, t-1}+a_{1, t} \\
r_{2, t}=0.1-0.1 r_{1, t-1}+0.3 r_{2, t-1}+a_{2, t}
\end{array}\right.
$$

where $a_t$ denotes a bivariate normal distribution with mean $0$ and covariance:

$$
\Sigma:=\left(\begin{array}{cc}
0.4 & -0.1 \\
-0.1 & 0.2
\end{array}\right)
$$

Any matrix operations can be computed in R. If any formulas require infinite series, you may approximate using the first 5 terms.

#### a. 

 Verify that the return series ${r_t}$ is a weakly stationary process.

 *Hint*: The “polyroot” function can be used to find all roots of a polynomial in R and the “eigen” function can be used to find all eigenvalues of a matrix in R.

 
```{r}
# Defining the coefficient matrix for the mean calculation.
A <- matrix(c(1 - 0.1, 0.1, -0.05, 1 - 0.3), nrow = 2, byrow = TRUE)

# Defining the constant terms.
B <- c(0.05, -0.1)

# Solving for mu (the mean of r1 and r2).
mu <- solve(A, B)

# Defining the coefficient matrix for the characteristic equation.
char_matrix <- matrix(c(-0.1, 0.1, -0.05, -0.3), nrow = 2, byrow = TRUE)

# Calculating the eigenvalues of the characteristic matrix.
eigenvalues <- eigen(char_matrix)$values

# Display the results.
print("Means of r1 and r2:")
mu

print("Eigenvalues of the characteristic matrix:")
eigenvalues

# Check if the absolute values of eigenvalues are less than 1 (inside the unit circle).
is_stationary <- all(abs(eigenvalues) < 1)

# Display the conclusion.
if (is_stationary) 
{
  print("The series is weakly stationary.")
} else 
{
  print("The series is not weakly stationary.")
}
```

#### b.

##### i.

What is the mean vector of the return series $r_t$?

```{r}
mu
```

##### ii.

What is the covariance matrix of the return series $r_t$?

```{r}
library(MASS) # For solving Yule-Walker equations

# Covariance matrix
Sigma <- matrix(c(0.4, -0.1, -0.1, 0.2), nrow = 2, byrow = TRUE)
phi <- matrix(c(0.1, -0.1, 0.05, 0.3), nrow = 2, byrow = TRUE)

# Solving Yule-Walker equations
cov_matrix <- solve(toeplitz(1:2), Sigma)

cov_matrix
```

##### iii.

What are the lag-1, lag-2, and lag-5 cross-correlation matrices of the return series $r_t$?

```{r}
# Create a function to compute the cross-correlation matrix for a given lag.
compute_cross_corr <- function(lag, phi, cov_matrix) 
{
    if (lag == 0) {
        return(cov_matrix)
    } else {
        return(phi %*% compute_cross_corr(lag - 1, phi, cov_matrix))
    }
}

lag1_corr <- compute_cross_corr(1, phi, cov_matrix)
lag2_corr <- compute_cross_corr(2, phi, cov_matrix)
lag5_corr <- compute_cross_corr(5, phi, cov_matrix)

lag1_corr
lag2_corr
lag5_corr
```

#### c.

Assume that $r_0 = (-0.02, 0.08)^{\top}$ and $a_0 = (-0.08, 0.1)^{\top}$. Compute the 1-, 2-, and 3-step ahead forecasts of the return series at the forecast origin $t = 1$. What are the covariance matrices of the associated forecast errors?

```{r}
# Initial values
r0 <- matrix(c(-0.02, 0.08), nrow = 2)
a0 <- matrix(c(-0.08, 0.1), nrow = 2)

constant <- matrix(c(-0.05, 0.1), nrow = 2)

# Function to compute the forecast.
forecast <- function(h, r0, a0, phi, constant) {
  if (h == 0) {
    return(r0)
  } else {
    return(phi %*% forecast(h - 1, r0, a0, phi, constant) + constant)
  }
}

# Compute forecasts.
forecast_1 <- forecast(1, r0, a0, phi, constant)
forecast_2 <- forecast(2, r0, a0, phi, constant)
forecast_3 <- forecast(3, r0, a0, phi, constant)

forecast_1
forecast_2
forecast_3

# Compute forecast errors.
forecast_error_cov_1 <- Sigma
forecast_error_cov_2 <- phi %*% Sigma %*% t(phi) + Sigma
forecast_error_cov_3 <- phi %*% forecast_error_cov_2 %*% t(phi) + Sigma

forecast_error_cov_1
forecast_error_cov_2
forecast_error_cov_3
```

#### d.

Create a report in pdf format and do the following:

##### i.

Simulate 1000 terms of this time series and plot the result.

```{r}
library(ggplot2)

# Model parameters.
phi <- matrix(c(0.1, -0.1, 0.05, 0.3), nrow = 2, byrow = TRUE)
constant <- c(-0.05, 0.1)
Sigma <- matrix(c(0.4, -0.1, -0.1, 0.2), nrow = 2, byrow = TRUE)
n <- 1000 # Number of terms to simulate

# Simulating the time series.
r <- matrix(nrow = n, ncol = 2)
r[1, ] <- c(-0.02, 0.08) # Initial value

# Simulating the time series
for (i in 2:n) {
  a_t <- mvrnorm(1, mu = c(0, 0), Sigma = Sigma)
  r[i, ] <- constant + phi %*% r[i - 1, ] + a_t
}

# Plotting the result.
df <- data.frame(Time = 1:n, r1 = r[, 1], r2 = r[, 2])

# Plotting the simulated time series.
plot(df$Time, df$r1, type = "l", col = "blue", xlab = "Time", ylab = "Returns", main = "Simulated Time Series")
lines(df$Time, df$r2, type = "l", col = "red")
legend("topright", legend = c("r1", "r2"), col = c("blue", "red"), lty = 1)
```

##### ii.

Using the generated time series, find the sample mean and covariance. How does your sample mean vector compare with that computed analytically?

##### iii.

Using the generated time series, find the sample lag-1, lag-2, and lag-5 crosscorrelation matrices.

##### iv.

Consider how you might use repeated simulations to forecast this time series. Use your method with 10,000 repeated simulations of the time series to forecast the 1-, 2-, and 3-step ahead returns with $r_0 = (−0.02, 0.08)^{\top}$ and $a_0 = (−0.08, 0.1)^{\top}$. What is the sample covariance of the errors? How do these values compare with those computed analytically?

